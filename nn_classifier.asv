function [precision, recall, f1] = nn_classifier(train_data, test,class)
    x = size(class);
    inputs = table2array(train_data(:,[1:236]));
    targets = table2array(train_data(:,237));
    inputs = inputs';
    targets = targets';
    class = class';
    test_data = table2array(test);
    test_data = test_data';

    hiddenLayerSize = 10;
    net = patternnet(hiddenLayerSize);
    net.divideParam.trainRatio = 80/100;
    net.divideParam.valRatio   = 20/100;
    net.divideParam.testRatio  = 0/100;
    net.trainParam.showWindow = false;
    [net,tr] = train(net,inputs,targets);
%     view(net);
    outputs = net(inputs);
    performance = perform(net,targets,outputs);

    tstOutputs = net(test_data);
    tstPerform = perform(net,class,tstOutputs);

%     [c,cm,ind,per] = confusion(class,tstOutputs);
%     tp = cm(2,2);
%     tn = cm(2,1);
%     fp = cm(1,1);
%     fn = cm(1,2);
    
    tp = 0;
    tn = 0;
    fp = 0;
    fn = 0;
    for i =1:1:x(1)
        a = class(i);
        b = label(i);
        if a==1 && b>=0.7
            tp = tp+1;
        elseif a==0 && b<=0.3
            tn = tn +1;
        elseif a==1 && b<=0.
            fn = fn +1; 
        elseif a==0 && b==1
            fp = fp +1; 
        end
    end

    precision = tp/(tp+fp);
    recall = tp/(tp+fn);
    f1 = (2*recall*precision)/(recall + precision);
    disp(strcat('Precision=',num2str(precision)));
    disp(strcat('Recall=',num2str(recall)));
    disp(strcat('F1 Score=',num2str(f1)));
end